import os
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", "core-engine"))
"""
MEV Analysis API Router

Handles MEV (Maximal Extractable Value) related endpoints including:
- MEV opportunity detection
- MEV pattern analysis
- MEV statistics and insights
"""

from datetime import datetime  # noqa: E402
from typing import Any, Optional  # noqa: E402
from uuid import UUID  # noqa: E402

from fastapi import APIRouter, Depends, HTTPException, Query  # noqa: E402
from pydantic import BaseModel, Field  # noqa: E402

try:
    from ..dependencies import get_current_user, get_database
except ImportError:
    async def get_current_user():
        return {"user": "anonymous"}
    
    async def get_database():
        return None  # noqa: E402
from ..models import PaginationParams  # noqa: E402

router = APIRouter(prefix="/api/v1/mev", tags=["mev"])


class MEVOpportunity(BaseModel):
    """MEV opportunity data model"""

    id: UUID
    transaction_hash: str
    chain_id: int
    mev_type: str  # sandwich, arbitrage, liquidation, frontrunning
    estimated_profit: str
    confidence_score: float
    block_number: int
    timestamp: datetime
    involved_addresses: list[str]
    metadata: dict[str, Any]


class MEVAnalysisRequest(BaseModel):
    """MEV analysis request"""

    transaction_hashes: list[str]
    analysis_type: str = Field(
        ..., description="sandwich, arbitrage, liquidation, frontrunning, all"
    )


class MEVAnalysisResponse(BaseModel):
    """MEV analysis response"""

    transaction_hash: str
    mev_detected: bool
    mev_patterns: list[str]
    confidence_scores: dict[str, float]
    estimated_profit: Optional[str]
    attack_vector: Optional[str]
    involved_addresses: list[str]
    recommendations: list[str]


class MEVStatsResponse(BaseModel):
    """MEV statistics response"""

    total_opportunities: int
    total_extracted_value: str
    opportunities_by_type: dict[str, int]
    top_extractors: list[dict[str, Any]]
    avg_profit_per_opportunity: str
    success_rate: float
    trends: dict[str, Any]


@router.get("/opportunities", response_model=list[MEVOpportunity])
async def get_mev_opportunities(
    pagination: PaginationParams = Depends(),
    mev_type: Optional[str] = Query(
        None, description="sandwich, arbitrage, liquidation, frontrunning"
    ),
    chain_id: Optional[int] = Query(None),
    min_profit: Optional[float] = Query(None),
    min_confidence: Optional[float] = Query(0.5, ge=0, le=1),
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """
    Get MEV opportunities with filtering.

    Supports filtering by:
    - MEV type (sandwich, arbitrage, liquidation, frontrunning)
    - Chain ID
    - Minimum profit threshold
    - Minimum confidence score
    """
    try:
        print(f"[DEBUG] MEV Opportunities query starting with limit={pagination.limit}")
        query_parts = [
            """
        SELECT mo.*
        FROM mev_opportunities mo
        WHERE 1=1
        """
        ]
        print("[DEBUG] Simplified query without JOIN")
        params = []
        param_count = 0

        if mev_type:
            param_count += 1
            query_parts.append(f"AND mo.mev_type = ${param_count}")
            params.append(mev_type)

        if chain_id:
            param_count += 1
            query_parts.append(f"AND mo.chain_id = ${param_count}")
            params.append(chain_id)

        if min_profit:
            param_count += 1
            query_parts.append(f"AND mo.estimated_profit::numeric >= ${param_count}")
            params.append(min_profit)

        if min_confidence:
            param_count += 1
            query_parts.append(f"AND mo.confidence_score >= ${param_count}")
            params.append(min_confidence)

        query_parts.append("ORDER BY t.timestamp DESC")

        param_count += 1
        query_parts.append(f"LIMIT ${param_count}")
        params.append(pagination.limit)

        param_count += 1
        query_parts.append(f"OFFSET ${param_count}")
        params.append(pagination.offset)

        query = " ".join(query_parts)

        async with db.acquire() as conn:
            rows = await conn.fetch(query, *params)
            return [dict(row) for row in rows]

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to retrieve MEV opportunities: {str(e)}"
        )


@router.get("/opportunities/{opportunity_id}", response_model=MEVOpportunity)
async def get_mev_opportunity_details(
    opportunity_id: UUID,
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """Get detailed information about a specific MEV opportunity."""
    try:
        query = """
        SELECT mo.*
        FROM mev_opportunities mo
        WHERE mo.id = $1
        """

        async with db.acquire() as conn:
            row = await conn.fetchrow(query, opportunity_id)

            if not row:
                raise HTTPException(status_code=404, detail="MEV opportunity not found")

            return dict(row)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to retrieve MEV opportunity details: {str(e)}",
        )


@router.post("/analyze", response_model=list[MEVAnalysisResponse])
async def analyze_transactions_for_mev(
    analysis_request: MEVAnalysisRequest,
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """
    Analyze transactions for MEV patterns.

    Performs real-time analysis on provided transaction hashes
    to detect various MEV patterns and estimate potential profits.
    """
    try:
        if len(analysis_request.transaction_hashes) > 100:
            raise HTTPException(
                status_code=400,
                detail="Cannot analyze more than 100 transactions at once",
            )

        results = []

        async with db.acquire() as conn:
            for tx_hash in analysis_request.transaction_hashes:
                # Get transaction data
                tx_query = """
                SELECT * FROM transactions_view WHERE hash = $1
                """
                tx_row = await conn.fetchrow(tx_query, tx_hash)

                if not tx_row:
                    results.append(
                        MEVAnalysisResponse(
                            transaction_hash=tx_hash,
                            mev_detected=False,
                            mev_patterns=[],
                            confidence_scores={},
                            involved_addresses=[],
                            recommendations=["Transaction not found"],
                        )
                    )
                    continue

                tx_data = dict(tx_row)

                # Perform MEV analysis
                analysis_result = await _analyze_transaction_mev(
                    tx_data, analysis_request.analysis_type, conn
                )

                results.append(analysis_result)

        return results

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to analyze transactions for MEV: {str(e)}"
        )


@router.get("/stats", response_model=MEVStatsResponse)
async def get_mev_stats(
    hours: int = Query(24, ge=1, le=168),
    chain_id: Optional[int] = Query(None),
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """Get MEV statistics and insights."""
    try:
        time_filter = f"created_at > NOW() - INTERVAL '{hours} hours'"
        chain_filter = f"AND chain_id = {chain_id}" if chain_id else ""

        async with db.acquire() as conn:
            # Total opportunities
            total_opportunities = await conn.fetchval(
                f"""
                SELECT COUNT(*) FROM mev_opportunities
                WHERE {time_filter} {chain_filter}
            """
            )

            # Total extracted value
            total_value = await conn.fetchval(
                f"""
                SELECT SUM(estimated_profit::numeric) FROM mev_opportunities
                WHERE {time_filter} {chain_filter}
            """
            )

            # Opportunities by type
            type_stats = await conn.fetch(
                f"""
                SELECT mev_type, COUNT(*) as count
                FROM mev_opportunities
                WHERE {time_filter} {chain_filter}
                GROUP BY mev_type
                ORDER BY count DESC
            """
            )

            # Top extractors
            extractor_stats = await conn.fetch(
                f"""
                SELECT
                    mo.involved_addresses[1] as extractor,
                    COUNT(*) as opportunity_count,
                    SUM(mo.estimated_profit::numeric) as total_profit
                FROM mev_opportunities mo
                WHERE {time_filter} {chain_filter}
                AND array_length(mo.involved_addresses, 1) > 0
                GROUP BY mo.involved_addresses[1]
                ORDER BY total_profit DESC
                LIMIT 10
            """
            )

            # Average profit
            avg_profit = await conn.fetchval(
                f"""
                SELECT AVG(estimated_profit::numeric) FROM mev_opportunities
                WHERE {time_filter} {chain_filter}
            """
            )

            # Success rate (placeholder calculation)
            success_rate = 0.75  # 75% success rate placeholder

            # Trends (placeholder)
            trends = {
                "hourly_opportunities": [5, 8, 12, 15, 20, 18, 14],
                "profit_trend": "increasing",
                "most_active_chain": 1,
                "emerging_patterns": ["multi-block arbitrage", "cross-chain MEV"],
            }

            return MEVStatsResponse(
                total_opportunities=total_opportunities or 0,
                total_extracted_value=str(total_value or 0),
                opportunities_by_type={
                    row["mev_type"]: row["count"] for row in type_stats
                },
                top_extractors=[
                    {
                        "address": row["extractor"],
                        "opportunity_count": row["opportunity_count"],
                        "total_profit": str(row["total_profit"]),
                    }
                    for row in extractor_stats
                ],
                avg_profit_per_opportunity=str(avg_profit or 0),
                success_rate=success_rate,
                trends=trends,
            )

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to retrieve MEV stats: {str(e)}"
        )


@router.get("/patterns/trending")
async def get_trending_mev_patterns(
    hours: int = Query(24, ge=1, le=168),
    limit: int = Query(10, ge=1, le=50),
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """Get trending MEV patterns and attack vectors."""
    try:
        async with db.acquire() as conn:
            # Get trending patterns
            pattern_stats = await conn.fetch(
                f"""
                SELECT
                    mev_type,
                    COUNT(*) as occurrence_count,
                    AVG(confidence_score) as avg_confidence,
                    SUM(estimated_profit::numeric) as total_profit,
                    COUNT(*) / EXTRACT(EPOCH FROM INTERVAL '{hours} hours') * 3600 as frequency_per_hour
                FROM mev_opportunities
                WHERE created_at > NOW() - INTERVAL '{hours} hours'
                GROUP BY mev_type
                ORDER BY occurrence_count DESC
                LIMIT $1
            """,
                limit,
            )

            # Get emerging attack vectors
            emerging_vectors = await conn.fetch(
                f"""
                SELECT DISTINCT
                    metadata->>'attack_vector' as vector,
                    COUNT(*) as count
                FROM mev_opportunities
                WHERE created_at > NOW() - INTERVAL '{hours} hours'
                AND metadata->>'attack_vector' IS NOT NULL
                GROUP BY metadata->>'attack_vector'
                ORDER BY count DESC
                LIMIT 5
            """
            )

            return {
                "trending_patterns": [
                    {
                        "pattern": row["mev_type"],
                        "occurrence_count": row["occurrence_count"],
                        "avg_confidence": round(float(row["avg_confidence"]), 3),
                        "total_profit": str(row["total_profit"]),
                        "frequency_per_hour": round(
                            float(row["frequency_per_hour"]), 2
                        ),
                    }
                    for row in pattern_stats
                ],
                "emerging_vectors": [
                    {"vector": row["vector"], "count": row["count"]}
                    for row in emerging_vectors
                ],
                "analysis_period_hours": hours,
                "timestamp": datetime.utcnow(),
            }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to retrieve trending MEV patterns: {str(e)}",
        )


@router.get("/protection/recommendations")
async def get_mev_protection_recommendations(
    address: Optional[str] = Query(None),
    transaction_hash: Optional[str] = Query(None),
    current_user: dict = Depends(get_current_user),
    db=Depends(get_database),
):
    """Get MEV protection recommendations for addresses or transactions."""
    try:
        recommendations = []

        if address:
            # Analyze address MEV exposure
            async with db.acquire() as conn:
                exposure_stats = await conn.fetchrow(
                    """
                    SELECT
                        COUNT(*) as total_transactions,
                        COUNT(*) FILTER (WHERE mev_patterns != '{}') as mev_affected,
                        AVG(risk_score) as avg_risk_score
                    FROM transactions_view
                    WHERE from_address = $1 OR to_address = $1
                    AND timestamp > extract(epoch from now() - interval '30 days')
                """,
                    address,
                )

                if exposure_stats and exposure_stats["total_transactions"] > 0:
                    mev_rate = (
                        exposure_stats["mev_affected"]
                        / exposure_stats["total_transactions"]
                    ) * 100

                    if mev_rate > 10:
                        recommendations.extend(
                            [
                                "Consider using MEV protection services",
                                "Implement private mempool solutions",
                                "Use flashloan protection mechanisms",
                            ]
                        )

                    if exposure_stats["avg_risk_score"] > 0.7:
                        recommendations.extend(
                            [
                                "Review transaction patterns",
                                "Consider address rotation strategies",
                            ]
                        )

        if transaction_hash:
            # Analyze specific transaction
            async with db.acquire() as conn:
                tx_analysis = await conn.fetchrow(
                    """
                    SELECT mev_patterns, risk_score, gas_price
                    FROM transactions_view
                    WHERE hash = $1
                """,
                    transaction_hash,
                )

                if tx_analysis:
                    if tx_analysis["mev_patterns"]:
                        recommendations.extend(
                            [
                                "Transaction shows MEV patterns",
                                "Consider timing optimization",
                                "Review gas price strategy",
                            ]
                        )

        # Default recommendations
        if not recommendations:
            recommendations = [
                "Monitor transaction patterns regularly",
                "Use MEV protection tools when available",
                "Stay informed about emerging MEV techniques",
                "Consider private transaction pools for sensitive operations",
            ]

        return {
            "recommendations": recommendations,
            "address": address,
            "transaction_hash": transaction_hash,
            "generated_at": datetime.utcnow(),
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate MEV protection recommendations: {str(e)}",
        )


# Helper functions
async def _analyze_transaction_mev(
    tx_data: dict, analysis_type: str, db_conn
) -> MEVAnalysisResponse:
    """Analyze a single transaction for MEV patterns."""

    mev_patterns = []
    confidence_scores = {}
    estimated_profit = None
    attack_vector = None
    involved_addresses = [tx_data["from_address"], tx_data["to_address"]]
    recommendations = []

    # Analyze based on type
    if analysis_type in ["sandwich", "all"]:
        sandwich_score = await _detect_sandwich_attack(tx_data, db_conn)
        if sandwich_score > 0.5:
            mev_patterns.append("sandwich")
            confidence_scores["sandwich"] = sandwich_score
            if sandwich_score > 0.8:
                attack_vector = "sandwich_attack"
                estimated_profit = "0.05 ETH"  # Placeholder

    if analysis_type in ["arbitrage", "all"]:
        arbitrage_score = await _detect_arbitrage(tx_data, db_conn)
        if arbitrage_score > 0.5:
            mev_patterns.append("arbitrage")
            confidence_scores["arbitrage"] = arbitrage_score
            if arbitrage_score > 0.7:
                estimated_profit = "0.1 ETH"  # Placeholder

    if analysis_type in ["liquidation", "all"]:
        liquidation_score = await _detect_liquidation(tx_data, db_conn)
        if liquidation_score > 0.5:
            mev_patterns.append("liquidation")
            confidence_scores["liquidation"] = liquidation_score

    if analysis_type in ["frontrunning", "all"]:
        frontrun_score = await _detect_frontrunning(tx_data, db_conn)
        if frontrun_score > 0.5:
            mev_patterns.append("frontrunning")
            confidence_scores["frontrunning"] = frontrun_score

    # Generate recommendations
    if mev_patterns:
        recommendations.extend(
            [
                "Consider using MEV protection services",
                "Review transaction timing and gas pricing",
                "Monitor for follow-up transactions",
            ]
        )
    else:
        recommendations.append("No immediate MEV concerns detected")

    return MEVAnalysisResponse(
        transaction_hash=tx_data["hash"],
        mev_detected=len(mev_patterns) > 0,
        mev_patterns=mev_patterns,
        confidence_scores=confidence_scores,
        estimated_profit=estimated_profit,
        attack_vector=attack_vector,
        involved_addresses=involved_addresses,
        recommendations=recommendations,
    )


async def _detect_sandwich_attack(tx_data: dict, db_conn) -> float:
    """Detect sandwich attack patterns."""
    # Placeholder implementation
    # In reality, this would analyze surrounding transactions
    return 0.3  # Low confidence placeholder


async def _detect_arbitrage(tx_data: dict, db_conn) -> float:
    """Detect arbitrage opportunities."""
    # Placeholder implementation
    return 0.2  # Low confidence placeholder


async def _detect_liquidation(tx_data: dict, db_conn) -> float:
    """Detect liquidation MEV."""
    # Placeholder implementation
    return 0.1  # Low confidence placeholder


async def _detect_frontrunning(tx_data: dict, db_conn) -> float:
    """Detect frontrunning patterns."""
    # Placeholder implementation
    return 0.25  # Low confidence placeholder
